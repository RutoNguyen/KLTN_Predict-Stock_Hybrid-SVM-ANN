{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 11:14:21.853 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\users\\nhat0\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "ename": "InternalHashError",
     "evalue": "module '__main__' has no attribute '__file__'\n\nWhile caching the body of `load_data()`, Streamlit encountered an\nobject of type `builtins.function`, which it does not know how to hash.\n\n**In this specific case, it's very likely you found a Streamlit bug so please\n[file a bug report here.]\n(https://github.com/streamlit/streamlit/issues/new/choose)**\n\nIn the meantime, you can try bypassing this error by registering a custom\nhash function via the `hash_funcs` keyword in @st.cache(). For example:\n\n```\n@st.cache(hash_funcs={builtins.function: my_hash_func})\ndef my_func(...):\n    ...\n```\n\nIf you don't know where the object of type `builtins.function` is coming\nfrom, try looking at the hash chain below for an object that you do recognize,\nthen pass that to `hash_funcs` instead:\n\n```\nObject of type builtins.function: <function load_data at 0x00000229E0D15820>\n```\n\nPlease see the `hash_funcs` [documentation]\n(https://docs.streamlit.io/library/advanced-features/caching#the-hash_funcs-parameter)\nfor more details.\n            ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\users\\nhat0\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\streamlit\\legacy_caching\\hashing.py:368\u001b[0m, in \u001b[0;36m_CodeHasher.to_bytes\u001b[1;34m(self, obj, context)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;66;03m# Hash the input\u001b[39;00m\n\u001b[1;32m--> 368\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (tname, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;66;03m# Hmmm... It's possible that the size calculation is wrong. When we\u001b[39;00m\n\u001b[0;32m    371\u001b[0m     \u001b[38;5;66;03m# call to_bytes inside _to_bytes things get double-counted.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\nhat0\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\streamlit\\legacy_caching\\hashing.py:634\u001b[0m, in \u001b[0;36m_CodeHasher._to_bytes\u001b[1;34m(self, obj, context)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m code \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file_should_be_hashed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mco_filename\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    635\u001b[0m     context \u001b[38;5;241m=\u001b[39m _get_context(obj)\n",
      "File \u001b[1;32mc:\\users\\nhat0\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\streamlit\\legacy_caching\\hashing.py:410\u001b[0m, in \u001b[0;36m_CodeHasher._file_should_be_hashed\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m file_util\u001b[38;5;241m.\u001b[39mfile_is_in_folder_glob(\n\u001b[1;32m--> 410\u001b[0m     filepath, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_main_script_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    411\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m file_util\u001b[38;5;241m.\u001b[39mfile_in_pythonpath(filepath)\n",
      "File \u001b[1;32mc:\\users\\nhat0\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\streamlit\\legacy_caching\\hashing.py:721\u001b[0m, in \u001b[0;36m_CodeHasher._get_main_script_directory\u001b[1;34m()\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[38;5;66;03m# This works because we set __main__.__file__ to the\u001b[39;00m\n\u001b[0;32m    720\u001b[0m \u001b[38;5;66;03m# script path in ScriptRunner.\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m main_path \u001b[38;5;241m=\u001b[39m \u001b[43m__main__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__file__\u001b[39;49m\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(main_path))\n",
      "\u001b[1;31mAttributeError\u001b[0m: module '__main__' has no attribute '__file__'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInternalHashError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstreamlit\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mst\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myfinance\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01myf\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#function calling local css sheet\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\KLTN\\MyProject\\code\\realTimeStreamlitDashBoard\\yfinance.py:32\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m data_load_state \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39mtext(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoad data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m#data: pd.DataFrame = load_data(select_stocks)\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselect_stocks\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     33\u001b[0m data_load_state\u001b[38;5;241m.\u001b[39mtext(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading data... done!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     35\u001b[0m st\u001b[38;5;241m.\u001b[39msubheader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaw data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\users\\nhat0\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\streamlit\\legacy_caching\\caching.py:573\u001b[0m, in \u001b[0;36mcache.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m show_spinner:\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m st\u001b[38;5;241m.\u001b[39mspinner(message):\n\u001b[1;32m--> 573\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_or_create_cached_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_or_create_cached_value()\n",
      "File \u001b[1;32mc:\\users\\nhat0\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\streamlit\\legacy_caching\\caching.py:498\u001b[0m, in \u001b[0;36mcache.<locals>.wrapped_func.<locals>.get_or_create_cached_value\u001b[1;34m()\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28;01mnonlocal\u001b[39;00m cache_key\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;66;03m# Delay generating the cache key until the first call.\u001b[39;00m\n\u001b[0;32m    494\u001b[0m     \u001b[38;5;66;03m# This way we can see values of globals, including functions\u001b[39;00m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;66;03m# defined after this one.\u001b[39;00m\n\u001b[0;32m    496\u001b[0m     \u001b[38;5;66;03m# If we generated the key earlier we would only hash those\u001b[39;00m\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;66;03m# globals by name, and miss changes in their code or value.\u001b[39;00m\n\u001b[1;32m--> 498\u001b[0m     cache_key \u001b[38;5;241m=\u001b[39m \u001b[43m_hash_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhash_funcs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;66;03m# First, get the cache that's attached to this function.\u001b[39;00m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;66;03m# This cache's key is generated (above) from the function's code.\u001b[39;00m\n\u001b[0;32m    502\u001b[0m mem_cache \u001b[38;5;241m=\u001b[39m _mem_caches\u001b[38;5;241m.\u001b[39mget_cache(cache_key, max_entries, ttl)\n",
      "File \u001b[1;32mc:\\users\\nhat0\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\streamlit\\legacy_caching\\caching.py:624\u001b[0m, in \u001b[0;36m_hash_func\u001b[1;34m(func, hash_funcs)\u001b[0m\n\u001b[0;32m    613\u001b[0m update_hash(\n\u001b[0;32m    614\u001b[0m     (func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m),\n\u001b[0;32m    615\u001b[0m     hasher\u001b[38;5;241m=\u001b[39mfunc_hasher,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    618\u001b[0m     hash_source\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    619\u001b[0m )\n\u001b[0;32m    621\u001b[0m \u001b[38;5;66;03m# Include the function's body in the hash. We *do* pass hash_funcs here,\u001b[39;00m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;66;03m# because this step will be hashing any objects referenced in the function\u001b[39;00m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;66;03m# body.\u001b[39;00m\n\u001b[1;32m--> 624\u001b[0m \u001b[43mupdate_hash\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhasher\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_hasher\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhash_funcs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhash_funcs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhash_reason\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHashReason\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCACHING_FUNC_BODY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhash_source\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    630\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m cache_key \u001b[38;5;241m=\u001b[39m func_hasher\u001b[38;5;241m.\u001b[39mhexdigest()\n\u001b[0;32m    632\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmem_cache key for \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m, cache_key\n\u001b[0;32m    634\u001b[0m )\n",
      "File \u001b[1;32mc:\\users\\nhat0\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\streamlit\\legacy_caching\\hashing.py:116\u001b[0m, in \u001b[0;36mupdate_hash\u001b[1;34m(val, hasher, hash_reason, hash_source, context, hash_funcs)\u001b[0m\n\u001b[0;32m    113\u001b[0m hash_stacks\u001b[38;5;241m.\u001b[39mcurrent\u001b[38;5;241m.\u001b[39mhash_source \u001b[38;5;241m=\u001b[39m hash_source\n\u001b[0;32m    115\u001b[0m ch \u001b[38;5;241m=\u001b[39m _CodeHasher(hash_funcs)\n\u001b[1;32m--> 116\u001b[0m \u001b[43mch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhasher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\nhat0\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\streamlit\\legacy_caching\\hashing.py:393\u001b[0m, in \u001b[0;36m_CodeHasher.update\u001b[1;34m(self, hasher, obj, context)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, hasher, obj: Any, context: Optional[Context] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;124;03m\"\"\"Update the provided hasher with the hash of an object.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    394\u001b[0m     hasher\u001b[38;5;241m.\u001b[39mupdate(b)\n",
      "File \u001b[1;32mc:\\users\\nhat0\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\streamlit\\legacy_caching\\hashing.py:382\u001b[0m, in \u001b[0;36m_CodeHasher.to_bytes\u001b[1;34m(self, obj, context)\u001b[0m\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 382\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InternalHashError(e, obj)\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;66;03m# In case an UnhashableTypeError (or other) error is thrown, clean up the\u001b[39;00m\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;66;03m# stack so we don't get false positives in future hashing calls\u001b[39;00m\n\u001b[0;32m    387\u001b[0m     hash_stacks\u001b[38;5;241m.\u001b[39mcurrent\u001b[38;5;241m.\u001b[39mpop()\n",
      "File \u001b[1;32mc:\\users\\nhat0\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\streamlit\\legacy_caching\\hashing.py:368\u001b[0m, in \u001b[0;36m_CodeHasher.to_bytes\u001b[1;34m(self, obj, context)\u001b[0m\n\u001b[0;32m    364\u001b[0m hash_stacks\u001b[38;5;241m.\u001b[39mcurrent\u001b[38;5;241m.\u001b[39mpush(obj)\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;66;03m# Hash the input\u001b[39;00m\n\u001b[1;32m--> 368\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (tname, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;66;03m# Hmmm... It's possible that the size calculation is wrong. When we\u001b[39;00m\n\u001b[0;32m    371\u001b[0m     \u001b[38;5;66;03m# call to_bytes inside _to_bytes things get double-counted.\u001b[39;00m\n\u001b[0;32m    372\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mgetsizeof(b)\n",
      "File \u001b[1;32mc:\\users\\nhat0\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\streamlit\\legacy_caching\\hashing.py:634\u001b[0m, in \u001b[0;36m_CodeHasher._to_bytes\u001b[1;34m(self, obj, context)\u001b[0m\n\u001b[0;32m    632\u001b[0m code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__code__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m code \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file_should_be_hashed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mco_filename\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    635\u001b[0m     context \u001b[38;5;241m=\u001b[39m _get_context(obj)\n\u001b[0;32m    636\u001b[0m     defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__defaults__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\users\\nhat0\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\streamlit\\legacy_caching\\hashing.py:410\u001b[0m, in \u001b[0;36m_CodeHasher._file_should_be_hashed\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_is_blacklisted:\n\u001b[0;32m    408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m file_util\u001b[38;5;241m.\u001b[39mfile_is_in_folder_glob(\n\u001b[1;32m--> 410\u001b[0m     filepath, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_main_script_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    411\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m file_util\u001b[38;5;241m.\u001b[39mfile_in_pythonpath(filepath)\n",
      "File \u001b[1;32mc:\\users\\nhat0\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\streamlit\\legacy_caching\\hashing.py:721\u001b[0m, in \u001b[0;36m_CodeHasher._get_main_script_directory\u001b[1;34m()\u001b[0m\n\u001b[0;32m    717\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m    719\u001b[0m \u001b[38;5;66;03m# This works because we set __main__.__file__ to the\u001b[39;00m\n\u001b[0;32m    720\u001b[0m \u001b[38;5;66;03m# script path in ScriptRunner.\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m main_path \u001b[38;5;241m=\u001b[39m \u001b[43m__main__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__file__\u001b[39;49m\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(main_path))\n",
      "\u001b[1;31mInternalHashError\u001b[0m: module '__main__' has no attribute '__file__'\n\nWhile caching the body of `load_data()`, Streamlit encountered an\nobject of type `builtins.function`, which it does not know how to hash.\n\n**In this specific case, it's very likely you found a Streamlit bug so please\n[file a bug report here.]\n(https://github.com/streamlit/streamlit/issues/new/choose)**\n\nIn the meantime, you can try bypassing this error by registering a custom\nhash function via the `hash_funcs` keyword in @st.cache(). For example:\n\n```\n@st.cache(hash_funcs={builtins.function: my_hash_func})\ndef my_func(...):\n    ...\n```\n\nIf you don't know where the object of type `builtins.function` is coming\nfrom, try looking at the hash chain below for an object that you do recognize,\nthen pass that to `hash_funcs` instead:\n\n```\nObject of type builtins.function: <function load_data at 0x00000229E0D15820>\n```\n\nPlease see the `hash_funcs` [documentation]\n(https://docs.streamlit.io/library/advanced-features/caching#the-hash_funcs-parameter)\nfor more details.\n            "
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "\n",
    "#function calling local css sheet\n",
    "def local_css(file_name):\n",
    "    with open(file_name) as f:\n",
    "        st.sidebar.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)\n",
    "\n",
    "#local css sheet\n",
    "local_css(\"style.css\")\n",
    "\n",
    "#ticker search feature in sidebar\n",
    "st.sidebar.subheader(\"\"\"Stock Search Web App\"\"\")\n",
    "selected_stock = st.sidebar.text_input(\"Enter a valid stock ticker...\", \"GOOG\")\n",
    "button_clicked = st.sidebar.button(\"GO\")\n",
    "\n",
    "#main function\n",
    "def main():\n",
    "    st.subheader(\"\"\"Daily **closing price** for \"\"\" + selected_stock)\n",
    "    #get data on searched ticker\n",
    "    stock_data = yf.Ticker(selected_stock)\n",
    "    #get historical data for searched ticker\n",
    "    stock_df = stock_data.history(period='1d', start='2020-01-01', end=None)\n",
    "    #print line chart with daily closing prices for searched ticker\n",
    "    st.line_chart(stock_df.Close)\n",
    "\n",
    "    st.subheader(\"\"\"Last **closing price** for \"\"\" + selected_stock)\n",
    "    #define variable today \n",
    "    today = datetime.today().strftime('%Y-%m-%d')\n",
    "    #get current date data for searched ticker\n",
    "    stock_lastprice = stock_data.history(period='1d', start=today, end=today)\n",
    "    #get current date closing price for searched ticker\n",
    "    last_price = (stock_lastprice.Close)\n",
    "    #if market is closed on current date print that there is no data available\n",
    "    if last_price.empty == True:\n",
    "        st.write(\"No data available at the moment\")\n",
    "    else:\n",
    "        st.write(last_price)\n",
    "    \n",
    "    #get daily volume for searched ticker\n",
    "    st.subheader(\"\"\"Daily **volume** for \"\"\" + selected_stock)\n",
    "    st.line_chart(stock_df.Volume)\n",
    "\n",
    "    #additional information feature in sidebar\n",
    "    st.sidebar.subheader(\"\"\"Display Additional Information\"\"\")\n",
    "    #checkbox to display stock actions for the searched ticker\n",
    "    actions = st.sidebar.checkbox(\"Stock Actions\")\n",
    "    if actions:\n",
    "        st.subheader(\"\"\"Stock **actions** for \"\"\" + selected_stock)\n",
    "        display_action = (stock_data.actions)\n",
    "        if display_action.empty == True:\n",
    "            st.write(\"No data available at the moment\")\n",
    "        else:\n",
    "            st.write(display_action)\n",
    "    \n",
    "    #checkbox to display quarterly financials for the searched ticker\n",
    "    financials = st.sidebar.checkbox(\"Quarterly Financials\")\n",
    "    if financials:\n",
    "        st.subheader(\"\"\"**Quarterly financials** for \"\"\" + selected_stock)\n",
    "        display_financials = (stock_data.quarterly_financials)\n",
    "        if display_financials.empty == True:\n",
    "            st.write(\"No data available at the moment\")\n",
    "        else:\n",
    "            st.write(display_financials)\n",
    "\n",
    "    #checkbox to display list of institutional shareholders for searched ticker\n",
    "    major_shareholders = st.sidebar.checkbox(\"Institutional Shareholders\")\n",
    "    if major_shareholders:\n",
    "        st.subheader(\"\"\"**Institutional investors** for \"\"\" + selected_stock)\n",
    "        display_shareholders = (stock_data.institutional_holders)\n",
    "        if display_shareholders.empty == True:\n",
    "            st.write(\"No data available at the moment\")\n",
    "        else:\n",
    "            st.write(display_shareholders)\n",
    "\n",
    "    #checkbox to display quarterly balance sheet for searched ticker\n",
    "    balance_sheet = st.sidebar.checkbox(\"Quarterly Balance Sheet\")\n",
    "    if balance_sheet:\n",
    "        st.subheader(\"\"\"**Quarterly balance sheet** for \"\"\" + selected_stock)\n",
    "        display_balancesheet = (stock_data.quarterly_balance_sheet)\n",
    "        if display_balancesheet.empty == True:\n",
    "            st.write(\"No data available at the moment\")\n",
    "        else:\n",
    "            st.write(display_balancesheet)\n",
    "\n",
    "    #checkbox to display quarterly cashflow for searched ticker\n",
    "    cashflow = st.sidebar.checkbox(\"Quarterly Cashflow\")\n",
    "    if cashflow:\n",
    "        st.subheader(\"\"\"**Quarterly cashflow** for \"\"\" + selected_stock)\n",
    "        display_cashflow = (stock_data.quarterly_cashflow)\n",
    "        if display_cashflow.empty == True:\n",
    "            st.write(\"No data available at the moment\")\n",
    "        else:\n",
    "            st.write(display_cashflow)\n",
    "\n",
    "    #checkbox to display quarterly earnings for searched ticker\n",
    "    earnings = st.sidebar.checkbox(\"Quarterly Earnings\")\n",
    "    if earnings:\n",
    "        st.subheader(\"\"\"**Quarterly earnings** for \"\"\" + selected_stock)\n",
    "        display_earnings = (stock_data.quarterly_earnings)\n",
    "        if display_earnings.empty == True:\n",
    "            st.write(\"No data available at the moment\")\n",
    "        else:\n",
    "            st.write(display_earnings)\n",
    "\n",
    "    #checkbox to display list of analysts recommendation for searched ticker\n",
    "    analyst_recommendation = st.sidebar.checkbox(\"Analysts Recommendation\")\n",
    "    if analyst_recommendation:\n",
    "        st.subheader(\"\"\"**Analysts recommendation** for \"\"\" + selected_stock)\n",
    "        display_analyst_rec = (stock_data.recommendations)\n",
    "        if display_analyst_rec.empty == True:\n",
    "            st.write(\"No data available at the moment\")\n",
    "        else:\n",
    "            st.write(display_analyst_rec)\n",
    "if button_clicked == \"GO\":\n",
    "    main()\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in c:\\users\\nhat0\\anaconda3\\lib\\site-packages (0.1.74)\n",
      "Requirement already satisfied: lxml>=4.5.1 in c:\\users\\nhat0\\anaconda3\\lib\\site-packages (from yfinance) (4.6.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\nhat0\\anaconda3\\lib\\site-packages (from yfinance) (1.1.3)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\nhat0\\anaconda3\\lib\\site-packages (from yfinance) (1.21.0)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\nhat0\\anaconda3\\lib\\site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: requests>=2.26 in c:\\users\\nhat0\\anaconda3\\lib\\site-packages (from yfinance) (2.28.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\nhat0\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->yfinance) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\nhat0\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nhat0\\anaconda3\\lib\\site-packages (from requests>=2.26->yfinance) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\nhat0\\anaconda3\\lib\\site-packages (from requests>=2.26->yfinance) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\nhat0\\anaconda3\\lib\\site-packages (from requests>=2.26->yfinance) (1.25.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nhat0\\anaconda3\\lib\\site-packages (from requests>=2.26->yfinance) (2.10)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nhat0\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting prophet\n",
      "  Downloading prophet-1.1.1-cp38-cp38-win_amd64.whl (12.1 MB)\n",
      "     --------------------------------------- 12.1/12.1 MB 14.5 MB/s eta 0:00:00\n",
      "Collecting wheel>=0.37.0\n",
      "  Using cached wheel-0.37.1-py2.py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: pandas>=1.0.4 in c:\\users\\nhat0\\anaconda3\\lib\\site-packages (from prophet) (1.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in c:\\users\\nhat0\\anaconda3\\lib\\site-packages (from prophet) (2.8.2)\n",
      "Requirement already satisfied: setuptools>=42 in c:\\users\\nhat0\\anaconda3\\lib\\site-packages (from prophet) (63.4.1)\n",
      "Collecting setuptools-git>=1.2\n",
      "  Using cached setuptools_git-1.2-py2.py3-none-any.whl (10 kB)\n",
      "Collecting convertdate>=2.1.2\n",
      "  Using cached convertdate-2.4.0-py3-none-any.whl (47 kB)\n",
      "Collecting LunarCalendar>=0.0.9\n",
      "  Using cached LunarCalendar-0.0.9-py2.py3-none-any.whl (18 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.1 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\nhat0\\anaconda3\\lib\\site-packages (from prophet) (1.21.0)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in c:\\users\\nhat0\\anaconda3\\lib\\site-packages (from prophet) (3.3.2)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in c:\\users\\nhat0\\anaconda3\\lib\\site-packages (from prophet) (4.64.1)\n",
      "Collecting cmdstanpy>=1.0.4\n",
      "  Using cached cmdstanpy-1.0.7-py3-none-any.whl (80 kB)\n",
      "Collecting holidays>=0.14.2\n",
      "  Using cached holidays-0.16-py3-none-any.whl (184 kB)\n",
      "Requirement already satisfied: ujson in c:\\users\\nhat0\\anaconda3\\lib\\site-packages (from cmdstanpy>=1.0.4->prophet) (4.0.1)\n",
      "Collecting pymeeus<=1,>=0.3.13\n",
      "  Using cached PyMeeus-0.5.11.tar.gz (5.4 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting korean-lunar-calendar\n",
      "  Using cached korean_lunar_calendar-0.3.1-py3-none-any.whl (9.0 kB)\n",
      "Collecting hijri-converter\n",
      "  Using cached hijri_converter-2.2.4-py3-none-any.whl (14 kB)\n",
      "Collecting ephem>=3.7.5.3\n",
      "  Downloading ephem-4.1.3-cp38-cp38-win_amd64.whl (1.4 MB)\n",
      "     ---------------------------------------- 1.4/1.4 MB 5.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pytz in c:\\users\\nhat0\\anaconda3\\lib\\site-packages (from LunarCalendar>=0.0.9->prophet) (2020.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\nhat0\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (9.2.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\nhat0\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (2022.9.14)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nhat0\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\nhat0\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\nhat0\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nhat0\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.0->prophet) (1.15.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nhat0\\anaconda3\\lib\\site-packages (from tqdm>=4.36.1->prophet) (0.4.4)\n",
      "Building wheels for collected packages: pymeeus\n",
      "  Building wheel for pymeeus (setup.py): started\n",
      "  Building wheel for pymeeus (setup.py): finished with status 'done'\n",
      "  Created wheel for pymeeus: filename=PyMeeus-0.5.11-py3-none-any.whl size=730976 sha256=24056f1b2b50955f6baef660f4b52479980428f40030d72fa1ea65a2219f3e9c\n",
      "  Stored in directory: c:\\users\\nhat0\\appdata\\local\\pip\\cache\\wheels\\a0\\8b\\b2\\810ae5a6f970c8be4725353400d643c90de1c0f023a9884ee7\n",
      "Successfully built pymeeus\n",
      "Installing collected packages: setuptools-git, pymeeus, korean-lunar-calendar, ephem, wheel, hijri-converter, convertdate, LunarCalendar, holidays, cmdstanpy, prophet\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.35.1\n",
      "    Uninstalling wheel-0.35.1:\n",
      "      Successfully uninstalled wheel-0.35.1\n",
      "Successfully installed LunarCalendar-0.0.9 cmdstanpy-1.0.7 convertdate-2.4.0 ephem-4.1.3 hijri-converter-2.2.4 holidays-0.16 korean-lunar-calendar-0.3.1 prophet-1.1.1 pymeeus-0.5.11 setuptools-git-1.2 wheel-0.37.1\n"
     ]
    }
   ],
   "source": [
    "!pip install prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf==3.20.0 in c:\\users\\nhat0\\appdata\\roaming\\python\\python38\\site-packages (3.20.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf==3.20.0 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'yfinance' has no attribute 'download' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-1584527be39e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0myfinance\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0myf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\KLTN\\MyProject\\code\\realTimeStreamlitDashBoard\\yfinance.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mdata_load_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Load data...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;31m#data: pd.DataFrame = load_data(select_stocks)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselect_stocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0mdata_load_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Loading data... done!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\KLTN\\MyProject\\code\\realTimeStreamlitDashBoard\\yfinance.py\u001b[0m in \u001b[0;36mload_data\u001b[1;34m(ticker)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m#goog = yf.Ticker(ticker)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m#data = goog.history(start=START, end=TODAY)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mticker\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'2021-1-10'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'2021-12-30'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_by\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ticker'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'yfinance' has no attribute 'download' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ttd = yf.Ticker(\"TTD\")\n",
    "print(ttd)\n",
    "ttd.info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
